{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/qq_26562641/article/details/50351538"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==0.22.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (0.22.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from scikit-learn==0.22.1) (1.16.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from scikit-learn==0.22.1) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from scikit-learn==0.22.1) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn==0.22.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/24/5fe7237b2eca13ee0cfb100bec8c23f4e69ce9df852a64b0493d49dae4e0/xgboost-0.90-py2.py3-none-manylinux1_x86_64.whl (142.8MB)\n",
      "\u001b[K     |████████████████████████████████| 142.8MB 34.6MB/s eta 0:00:01   |██████▋                         | 29.4MB 6.8MB/s eta 0:00:17     |███████                         | 31.2MB 6.8MB/s eta 0:00:17     |██████████████████▌             | 82.6MB 38.2MB/s eta 0:00:02     |████████████████████████████▍   | 126.7MB 32.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from xgboost) (1.16.2)\n",
      "Requirement already satisfied: scipy in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from xgboost) (1.2.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.90\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/9d/ddcb2f43aca194987f1a99e27edf41cf9bc39ea750c3371c2a62698c509a/lightgbm-2.3.1-py2.py3-none-manylinux1_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 13.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from lightgbm) (0.20.1)\n",
      "Requirement already satisfied: numpy in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from lightgbm) (1.16.2)\n",
      "Requirement already satisfied: scipy in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from lightgbm) (1.2.1)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn as skl\n",
    "print(skl.__version__)\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import neural_network\n",
    "from sklearn import ensemble \n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hyperplane(clf, X, y, \n",
    "                    h=0.02, \n",
    "                    draw_sv=True, \n",
    "                    title='hyperplan'):\n",
    "    # create a mesh to plot in\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap='hot', alpha=0.5)\n",
    "\n",
    "    markers = ['o', 's', '^']\n",
    "    colors = ['b', 'r', 'c']\n",
    "    labels = np.unique(y)\n",
    "    for label in labels:\n",
    "        plt.scatter(X[y==label][:, 0], \n",
    "                    X[y==label][:, 1], \n",
    "                    c=colors[label], \n",
    "                    marker=markers[label])\n",
    "    if draw_sv:\n",
    "        sv = clf.support_vectors_\n",
    "        plt.scatter(sv[:, 0], sv[:, 1], c='y', marker='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/cheat-sheet.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/IRIS.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Iris-setosa</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris-virginica</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 sepal_length  sepal_width  petal_length  petal_width\n",
       "species                                                              \n",
       "Iris-setosa                50           50            50           50\n",
       "Iris-versicolor            50           50            50           50\n",
       "Iris-virginica             50           50            50           50"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['species']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    0\n",
       "sepal_width     0\n",
       "petal_length    0\n",
       "petal_width     0\n",
       "species         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据缺失情况\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 查看分布，其中sepal_length 和 sepal_width符合正态分布\n",
    "plt.figure()\n",
    "for index, colmn in enumerate(df.columns[:4]):\n",
    "    plt.subplot(2, 2, index + 1)\n",
    "    sns.distplot(df[colmn])\n",
    "    plt.title(colmn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "# 转化为数值标签\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['species'])\n",
    "print(le.classes_)\n",
    "df['species'] = le.transform(df['species'])\n",
    "df.groupby(['species']).count()\n",
    "x = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "y = df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80377277, 0.55160877, 0.22064351, 0.0315205 ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data rescaling\n",
    "# https://machinelearningmastery.com/rescaling-data-for-machine-learning-in-python-with-scikit-learn/\n",
    "x = preprocessing.normalize(x)\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "112\n"
     ]
    }
   ],
   "source": [
    "# split train set, test set and validation set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "print(len(x_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8421052631578947"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 岭回归分类\n",
    "# 原理：在ols的基础上采用L2正则化。ols默认参数都是独立的，否则会导致多重共线性的问题，使用L2正则化能够一定程度上缓解\n",
    "#      将label分解为正负例，对每个问题视为回归问题，分类结果取决于回归的正负。对于多分类问题则视为多输出回归问题，分类结果取决于最高得分\n",
    "#      有时被视作搭载线性核的SVM分类器\n",
    "# 优点：比logistic快\n",
    "# 输入数据：残差符合正态分布\n",
    "# 主要参数 alpha：用于约束权重的收敛，越大越收敛，对于多重共线性越鲁棒，越小越发散\n",
    "# 构造模型\n",
    "clf = linear_model.RidgeClassifier(alpha=0.7)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=RidgeClassifier(alpha=1.0, class_weight=None,\n",
       "                                       copy_X=True, fit_intercept=True,\n",
       "                                       max_iter=None, normalize=False,\n",
       "                                       random_state=None, solver='auto',\n",
       "                                       tol=0.001),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
       "                                   1.0, 1.1, 1.2, 1.3, 1.4, 1.5]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 选择超参数\n",
    "parameters = {'alpha':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5]}\n",
    "clf = linear_model.RidgeClassifier()\n",
    "clf2 = GridSearchCV(clf, parameters)\n",
    "clf2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006406</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.008289</td>\n",
       "      <td>0.011074</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.857312</td>\n",
       "      <td>0.041968</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'alpha': 0.2}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.857312</td>\n",
       "      <td>0.041968</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005030</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 0.3}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.857312</td>\n",
       "      <td>0.041968</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'alpha': 0.4}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.857312</td>\n",
       "      <td>0.041968</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004994</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.857312</td>\n",
       "      <td>0.041968</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004994</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'alpha': 0.6}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.857312</td>\n",
       "      <td>0.041968</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005002</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 0.7}</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.866008</td>\n",
       "      <td>0.027651</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004991</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'alpha': 0.8}</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.856917</td>\n",
       "      <td>0.033738</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004998</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'alpha': 0.9}</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.856917</td>\n",
       "      <td>0.033738</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.856917</td>\n",
       "      <td>0.033738</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>1.1</td>\n",
       "      <td>{'alpha': 1.1}</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.856917</td>\n",
       "      <td>0.033738</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.005060</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.001589</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>1.2</td>\n",
       "      <td>{'alpha': 1.2}</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.856917</td>\n",
       "      <td>0.033738</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.005016</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>1.3</td>\n",
       "      <td>{'alpha': 1.3}</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.856917</td>\n",
       "      <td>0.033738</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.004978</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>1.4</td>\n",
       "      <td>{'alpha': 1.4}</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.856917</td>\n",
       "      <td>0.033738</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.004994</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>1.5</td>\n",
       "      <td>{'alpha': 1.5}</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.036697</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.006406      0.000793         0.008289        0.011074         0.1   \n",
       "1        0.005076      0.000103         0.001615        0.000039         0.2   \n",
       "2        0.005030      0.000053         0.001599        0.000017         0.3   \n",
       "3        0.004986      0.000021         0.001590        0.000024         0.4   \n",
       "4        0.004994      0.000029         0.001588        0.000020         0.5   \n",
       "5        0.004994      0.000037         0.001600        0.000036         0.6   \n",
       "6        0.005002      0.000026         0.001597        0.000023         0.7   \n",
       "7        0.004991      0.000030         0.001585        0.000027         0.8   \n",
       "8        0.004998      0.000039         0.001591        0.000027         0.9   \n",
       "9        0.004966      0.000016         0.001595        0.000022           1   \n",
       "10       0.005088      0.000221         0.001597        0.000020         1.1   \n",
       "11       0.005060      0.000054         0.001589        0.000037         1.2   \n",
       "12       0.005016      0.000032         0.001604        0.000028         1.3   \n",
       "13       0.004978      0.000013         0.001595        0.000031         1.4   \n",
       "14       0.004994      0.000012         0.001612        0.000040         1.5   \n",
       "\n",
       "            params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0   {'alpha': 0.1}           0.782609           0.913043           0.863636   \n",
       "1   {'alpha': 0.2}           0.782609           0.913043           0.863636   \n",
       "2   {'alpha': 0.3}           0.782609           0.913043           0.863636   \n",
       "3   {'alpha': 0.4}           0.782609           0.913043           0.863636   \n",
       "4   {'alpha': 0.5}           0.782609           0.913043           0.863636   \n",
       "5   {'alpha': 0.6}           0.782609           0.913043           0.863636   \n",
       "6   {'alpha': 0.7}           0.826087           0.913043           0.863636   \n",
       "7   {'alpha': 0.8}           0.826087           0.913043           0.863636   \n",
       "8   {'alpha': 0.9}           0.826087           0.913043           0.863636   \n",
       "9   {'alpha': 1.0}           0.826087           0.913043           0.863636   \n",
       "10  {'alpha': 1.1}           0.826087           0.913043           0.863636   \n",
       "11  {'alpha': 1.2}           0.826087           0.913043           0.863636   \n",
       "12  {'alpha': 1.3}           0.826087           0.913043           0.863636   \n",
       "13  {'alpha': 1.4}           0.826087           0.913043           0.863636   \n",
       "14  {'alpha': 1.5}           0.826087           0.913043           0.818182   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.863636           0.863636         0.857312        0.041968   \n",
       "1            0.863636           0.863636         0.857312        0.041968   \n",
       "2            0.863636           0.863636         0.857312        0.041968   \n",
       "3            0.863636           0.863636         0.857312        0.041968   \n",
       "4            0.863636           0.863636         0.857312        0.041968   \n",
       "5            0.863636           0.863636         0.857312        0.041968   \n",
       "6            0.863636           0.863636         0.866008        0.027651   \n",
       "7            0.818182           0.863636         0.856917        0.033738   \n",
       "8            0.818182           0.863636         0.856917        0.033738   \n",
       "9            0.818182           0.863636         0.856917        0.033738   \n",
       "10           0.818182           0.863636         0.856917        0.033738   \n",
       "11           0.818182           0.863636         0.856917        0.033738   \n",
       "12           0.818182           0.863636         0.856917        0.033738   \n",
       "13           0.818182           0.863636         0.856917        0.033738   \n",
       "14           0.818182           0.863636         0.847826        0.036697   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 2  \n",
       "1                 2  \n",
       "2                 2  \n",
       "3                 2  \n",
       "4                 2  \n",
       "5                 2  \n",
       "6                 1  \n",
       "7                 8  \n",
       "8                 8  \n",
       "9                 8  \n",
       "10                8  \n",
       "11                8  \n",
       "12                8  \n",
       "13                8  \n",
       "14               15  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预测结果\n",
    "pd.DataFrame(clf2.cv_results_)\n",
    "# alpha=0.7时模型最优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.88      0.64      0.74        11\n",
      "           2       0.73      0.92      0.81        12\n",
      "\n",
      "    accuracy                           0.87        38\n",
      "   macro avg       0.87      0.85      0.85        38\n",
      "weighted avg       0.88      0.87      0.87        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 各种指标\n",
    "print(metrics.classification_report(y_test, clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[23  0]\n",
      "  [ 0 15]]\n",
      "\n",
      " [[26  1]\n",
      "  [ 4  7]]\n",
      "\n",
      " [[22  4]\n",
      "  [ 1 11]]]\n"
     ]
    }
   ],
   "source": [
    "# TP TN FP FN\n",
    "metrics.multilabel_confusion_matrix(y_test, clf.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average persion:  0.8888888888888888\n",
      "F1 score:  0.8083333333333332\n",
      "recall:  0.8181818181818182\n",
      "acc:  0.8421052631578947\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(x_test)\n",
    "print('average persion: ', metrics.precision_score(y_test, pred, average='macro'))\n",
    "print('F1 score: ', metrics.f1_score(y_test, pred, average='macro'))\n",
    "print('recall: ', metrics.recall_score(y_test, pred, average='macro'))\n",
    "print('acc: ', metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8157894736842105"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic分类\n",
    "# 原理：使用log函数将因变量转化为概率值（0~1，越接近1越可能是正例），进行分类。在多分类情况下采用ovr，即当前类和其他类作0-1预测\n",
    "# 优点：可选l1、l2、Elastic-net正则项、简单快速\n",
    "# 主要参数 penalty:正则化项，可选l1、l2、elasticnet  C：正则化强度，默认1  solver：优化算法  multi-class: 可选ovr、multinomial l1-ratio：只用于选择elasticnet时使用，平衡l1-l2\n",
    "# 构造模型\n",
    "lr = linear_model.LogisticRegression(multi_class='ovr')\n",
    "lr.fit(x_train, y_train)\n",
    "lr.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012365</td>\n",
       "      <td>0.005961</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>7.783782e-05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.660474</td>\n",
       "      <td>0.024185</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009872</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>1.924107e-05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'C': 0.2}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.142966</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011668</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>6.615847e-06</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'C': 0.3}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.792885</td>\n",
       "      <td>0.111497</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012798</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>3.330884e-05</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'C': 0.4}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.801976</td>\n",
       "      <td>0.118527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012887</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>1.959702e-05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'C': 0.5}</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.784190</td>\n",
       "      <td>0.103172</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.013198</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>9.172146e-07</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'C': 0.6}</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.775494</td>\n",
       "      <td>0.097273</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.012868</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>3.897671e-05</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'C': 0.7}</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.757312</td>\n",
       "      <td>0.087059</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.013343</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>2.094797e-05</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'C': 0.8}</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.757312</td>\n",
       "      <td>0.087059</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.014209</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>2.488679e-05</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'C': 0.9}</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.757312</td>\n",
       "      <td>0.087059</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.016207</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>4.344795e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1.0}</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.757312</td>\n",
       "      <td>0.087059</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.014989</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>5.728797e-06</td>\n",
       "      <td>1.1</td>\n",
       "      <td>{'C': 1.1}</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.784585</td>\n",
       "      <td>0.055954</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.016184</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>2.396551e-05</td>\n",
       "      <td>1.2</td>\n",
       "      <td>{'C': 1.2}</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.793676</td>\n",
       "      <td>0.049187</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.015896</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>4.587942e-05</td>\n",
       "      <td>1.3</td>\n",
       "      <td>{'C': 1.3}</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.793676</td>\n",
       "      <td>0.049187</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.015202</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>1.413048e-05</td>\n",
       "      <td>1.4</td>\n",
       "      <td>{'C': 1.4}</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.793676</td>\n",
       "      <td>0.049187</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.015614</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>3.620824e-06</td>\n",
       "      <td>1.5</td>\n",
       "      <td>{'C': 1.5}</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.793676</td>\n",
       "      <td>0.049187</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.012365      0.005961         0.000703    7.783782e-05     0.1   \n",
       "1        0.009872      0.000259         0.000677    1.924107e-05     0.2   \n",
       "2        0.011668      0.000213         0.000664    6.615847e-06     0.3   \n",
       "3        0.012798      0.000214         0.000689    3.330884e-05     0.4   \n",
       "4        0.012887      0.000084         0.000680    1.959702e-05     0.5   \n",
       "5        0.013198      0.000213         0.000664    9.172146e-07     0.6   \n",
       "6        0.012868      0.000099         0.000696    3.897671e-05     0.7   \n",
       "7        0.013343      0.000262         0.000687    2.094797e-05     0.8   \n",
       "8        0.014209      0.000284         0.000681    2.488679e-05     0.9   \n",
       "9        0.016207      0.003483         0.000711    4.344795e-05       1   \n",
       "10       0.014989      0.000185         0.000670    5.728797e-06     1.1   \n",
       "11       0.016184      0.000218         0.000685    2.396551e-05     1.2   \n",
       "12       0.015896      0.000290         0.000736    4.587942e-05     1.3   \n",
       "13       0.015202      0.000720         0.000674    1.413048e-05     1.4   \n",
       "14       0.015614      0.000225         0.000666    3.620824e-06     1.5   \n",
       "\n",
       "        params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0   {'C': 0.1}           0.652174           0.695652           0.636364   \n",
       "1   {'C': 0.2}           0.956522           0.956522           0.681818   \n",
       "2   {'C': 0.3}           0.913043           0.869565           0.863636   \n",
       "3   {'C': 0.4}           0.913043           0.869565           0.909091   \n",
       "4   {'C': 0.5}           0.869565           0.869565           0.863636   \n",
       "5   {'C': 0.6}           0.869565           0.826087           0.863636   \n",
       "6   {'C': 0.7}           0.869565           0.826087           0.772727   \n",
       "7   {'C': 0.8}           0.869565           0.826087           0.772727   \n",
       "8   {'C': 0.9}           0.869565           0.826087           0.772727   \n",
       "9   {'C': 1.0}           0.869565           0.826087           0.772727   \n",
       "10  {'C': 1.1}           0.869565           0.826087           0.772727   \n",
       "11  {'C': 1.2}           0.869565           0.826087           0.772727   \n",
       "12  {'C': 1.3}           0.869565           0.826087           0.772727   \n",
       "13  {'C': 1.4}           0.869565           0.826087           0.772727   \n",
       "14  {'C': 1.5}           0.869565           0.826087           0.772727   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.681818           0.636364         0.660474        0.024185   \n",
       "1            0.681818           0.636364         0.782609        0.142966   \n",
       "2            0.681818           0.636364         0.792885        0.111497   \n",
       "3            0.681818           0.636364         0.801976        0.118527   \n",
       "4            0.681818           0.636364         0.784190        0.103172   \n",
       "5            0.681818           0.636364         0.775494        0.097273   \n",
       "6            0.681818           0.636364         0.757312        0.087059   \n",
       "7            0.681818           0.636364         0.757312        0.087059   \n",
       "8            0.681818           0.636364         0.757312        0.087059   \n",
       "9            0.681818           0.636364         0.757312        0.087059   \n",
       "10           0.727273           0.727273         0.784585        0.055954   \n",
       "11           0.727273           0.772727         0.793676        0.049187   \n",
       "12           0.727273           0.772727         0.793676        0.049187   \n",
       "13           0.727273           0.772727         0.793676        0.049187   \n",
       "14           0.727273           0.772727         0.793676        0.049187   \n",
       "\n",
       "    rank_test_score  \n",
       "0                15  \n",
       "1                 9  \n",
       "2                 6  \n",
       "3                 1  \n",
       "4                 8  \n",
       "5                10  \n",
       "6                11  \n",
       "7                11  \n",
       "8                11  \n",
       "9                11  \n",
       "10                7  \n",
       "11                2  \n",
       "12                2  \n",
       "13                2  \n",
       "14                2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 选择超参数\n",
    "parameters = {'C':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5]}\n",
    "lr = linear_model.LogisticRegression(multi_class='ovr')\n",
    "lr2 = GridSearchCV(lr, parameters)\n",
    "lr2.fit(x_train, y_train)\n",
    "pd.DataFrame(lr2.cv_results_)\n",
    "# 0.4结果最好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.23593164 0.37865603 0.38541233]]\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "# 预测结果\n",
    "lr = linear_model.LogisticRegression(multi_class='ovr', C=0.4)\n",
    "lr.fit(x_train, y_train)\n",
    "print(lr.predict_proba(x_test[:1]))\n",
    "print(lr.predict(x_test[:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      0.36      0.53        11\n",
      "           2       0.63      1.00      0.77        12\n",
      "\n",
      "    accuracy                           0.82        38\n",
      "   macro avg       0.88      0.79      0.77        38\n",
      "weighted avg       0.88      0.82      0.79        38\n",
      "\n",
      "average persion:  0.8771929824561404\n",
      "F1 score:  0.7691756272401434\n",
      "recall:  0.787878787878788\n",
      "acc:  0.8157894736842105\n"
     ]
    }
   ],
   "source": [
    "# 模型检验\n",
    "pred = lr.predict(x_test)\n",
    "print(metrics.classification_report(y_test, pred))\n",
    "print('average persion: ', metrics.precision_score(y_test, pred, average='macro'))\n",
    "print('F1 score: ', metrics.f1_score(y_test, pred, average='macro'))\n",
    "print('recall: ', metrics.recall_score(y_test, pred, average='macro'))\n",
    "print('acc: ', metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 支持向量机\n",
    "# 原理：在分类问题中构建超平面，边界为1和-1，由支持向量的线性组合而来\n",
    "# 优点： 适用于高维数据求解、维度大于样本数的数据、可以使用不同的核函数、非线性求解\n",
    "# 缺点： 不适合用于大规模数据（慢）\n",
    "# 主要参数 C：惩罚系数，默认1 kernel：核函数，可选linear、poly、rbf、sigmoid、或者其他callable函数，默认rbf gamma：决定了映射空间的分布越大则支持向量越多，影响训练速度\n",
    "# 构造模型\n",
    "mysvm = svm.SVC()\n",
    "mysvm.fit(x_train, y_train)\n",
    "mysvm.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>2.468294e-05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 0.1, 'kernel': 'linear'}</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.475494</td>\n",
       "      <td>0.168810</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>1.939233e-05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.788142</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>1.687990e-05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.1, 'kernel': 'poly'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964032</td>\n",
       "      <td>0.052947</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>2.322809e-05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 0.1, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.475494</td>\n",
       "      <td>0.168810</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>6.033451e-06</td>\n",
       "      <td>0.2</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 0.2, 'kernel': 'linear'}</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.493281</td>\n",
       "      <td>0.174651</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>2.328216e-06</td>\n",
       "      <td>0.2</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.2, 'kernel': 'rbf'}</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.788142</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>1.715063e-05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.2, 'kernel': 'poly'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964032</td>\n",
       "      <td>0.052947</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>4.313729e-06</td>\n",
       "      <td>0.2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 0.2, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.475494</td>\n",
       "      <td>0.168810</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>1.363654e-05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 0.30000000000000004, 'kernel': 'linear'}</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.788142</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>2.421159e-05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.30000000000000004, 'kernel': 'rbf'}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919368</td>\n",
       "      <td>0.101315</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>2.133014e-05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.30000000000000004, 'kernel': 'poly'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972727</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>2.299651e-05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 0.30000000000000004, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.475494</td>\n",
       "      <td>0.168810</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001490</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>2.311977e-05</td>\n",
       "      <td>0.4</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 0.4, 'kernel': 'linear'}</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.788142</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001517</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>1.793668e-05</td>\n",
       "      <td>0.4</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.4, 'kernel': 'rbf'}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964427</td>\n",
       "      <td>0.033817</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>3.367699e-05</td>\n",
       "      <td>0.4</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.4, 'kernel': 'poly'}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964032</td>\n",
       "      <td>0.052947</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>4.009064e-05</td>\n",
       "      <td>0.4</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 0.4, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.475494</td>\n",
       "      <td>0.168810</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002888</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>4.537761e-04</td>\n",
       "      <td>0.5</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 0.5, 'kernel': 'linear'}</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.788142</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.002128</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>1.591636e-05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.5, 'kernel': 'rbf'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964032</td>\n",
       "      <td>0.052947</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>2.082015e-05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.5, 'kernel': 'poly'}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964032</td>\n",
       "      <td>0.052947</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001987</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>8.229552e-06</td>\n",
       "      <td>0.5</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 0.5, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.475494</td>\n",
       "      <td>0.168810</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>1.593164e-05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 0.6, 'kernel': 'linear'}</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.788142</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>6.362516e-06</td>\n",
       "      <td>0.6</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.6, 'kernel': 'rbf'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964032</td>\n",
       "      <td>0.052947</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.390076e-05</td>\n",
       "      <td>0.6</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.6, 'kernel': 'poly'}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964032</td>\n",
       "      <td>0.052947</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.001983</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>4.028075e-06</td>\n",
       "      <td>0.6</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 0.6, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.475494</td>\n",
       "      <td>0.168810</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>1.939116e-05</td>\n",
       "      <td>0.7</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 0.7000000000000001, 'kernel': 'linear'}</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.788142</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>1.334241e-05</td>\n",
       "      <td>0.7</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.7000000000000001, 'kernel': 'rbf'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964032</td>\n",
       "      <td>0.052947</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>2.831465e-06</td>\n",
       "      <td>0.7</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.7000000000000001, 'kernel': 'poly'}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964032</td>\n",
       "      <td>0.052947</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>4.207531e-06</td>\n",
       "      <td>0.7</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 0.7000000000000001, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.475494</td>\n",
       "      <td>0.168810</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>2.177481e-05</td>\n",
       "      <td>0.8</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 0.8, 'kernel': 'linear'}</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.788142</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>1.795126e-05</td>\n",
       "      <td>0.8</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.8, 'kernel': 'rbf'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964032</td>\n",
       "      <td>0.052947</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>1.861706e-05</td>\n",
       "      <td>0.8</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.8, 'kernel': 'poly'}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964032</td>\n",
       "      <td>0.052947</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>6.480426e-06</td>\n",
       "      <td>0.8</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 0.8, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.475494</td>\n",
       "      <td>0.168810</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>1.480839e-05</td>\n",
       "      <td>0.9</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 0.9, 'kernel': 'linear'}</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.788142</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>1.426166e-05</td>\n",
       "      <td>0.9</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.9, 'kernel': 'rbf'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964032</td>\n",
       "      <td>0.052947</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>6.468134e-07</td>\n",
       "      <td>0.9</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 0.9, 'kernel': 'poly'}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964032</td>\n",
       "      <td>0.052947</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>2.022093e-05</td>\n",
       "      <td>0.9</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 0.9, 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.475494</td>\n",
       "      <td>0.168810</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.001709      0.000223         0.000770    2.468294e-05     0.1   \n",
       "1        0.001695      0.000045         0.000799    1.939233e-05     0.1   \n",
       "2        0.001326      0.000019         0.000730    1.687990e-05     0.1   \n",
       "3        0.002009      0.000014         0.000859    2.322809e-05     0.1   \n",
       "4        0.001482      0.000019         0.000746    6.033451e-06     0.2   \n",
       "5        0.001598      0.000041         0.000774    2.328216e-06     0.2   \n",
       "6        0.001317      0.000040         0.000736    1.715063e-05     0.2   \n",
       "7        0.002021      0.000022         0.000838    4.313729e-06     0.2   \n",
       "8        0.001505      0.000044         0.000751    1.363654e-05     0.3   \n",
       "9        0.001543      0.000033         0.000784    2.421159e-05     0.3   \n",
       "10       0.001304      0.000022         0.000734    2.133014e-05     0.3   \n",
       "11       0.002073      0.000014         0.000867    2.299651e-05     0.3   \n",
       "12       0.001490      0.000031         0.000756    2.311977e-05     0.4   \n",
       "13       0.001517      0.000017         0.000781    1.793668e-05     0.4   \n",
       "14       0.001315      0.000028         0.000747    3.367699e-05     0.4   \n",
       "15       0.003252      0.002459         0.000867    4.009064e-05     0.4   \n",
       "16       0.002888      0.001742         0.001023    4.537761e-04     0.5   \n",
       "17       0.002128      0.001337         0.000764    1.591636e-05     0.5   \n",
       "18       0.001266      0.000026         0.000713    2.082015e-05     0.5   \n",
       "19       0.001987      0.000024         0.000821    8.229552e-06     0.5   \n",
       "20       0.001407      0.000017         0.000727    1.593164e-05     0.6   \n",
       "21       0.001447      0.000019         0.000748    6.362516e-06     0.6   \n",
       "22       0.001260      0.000022         0.000700    1.390076e-05     0.6   \n",
       "23       0.001983      0.000023         0.000821    4.028075e-06     0.6   \n",
       "24       0.001398      0.000023         0.000725    1.939116e-05     0.7   \n",
       "25       0.001427      0.000016         0.000749    1.334241e-05     0.7   \n",
       "26       0.001261      0.000016         0.000696    2.831465e-06     0.7   \n",
       "27       0.002025      0.000053         0.000817    4.207531e-06     0.7   \n",
       "28       0.001372      0.000020         0.000737    2.177481e-05     0.8   \n",
       "29       0.001420      0.000023         0.000752    1.795126e-05     0.8   \n",
       "30       0.001245      0.000011         0.000714    1.861706e-05     0.8   \n",
       "31       0.001995      0.000005         0.000820    6.480426e-06     0.8   \n",
       "32       0.001369      0.000021         0.000726    1.480839e-05     0.9   \n",
       "33       0.001407      0.000021         0.000753    1.426166e-05     0.9   \n",
       "34       0.001248      0.000011         0.000699    6.468134e-07     0.9   \n",
       "35       0.001994      0.000015         0.000838    2.022093e-05     0.9   \n",
       "\n",
       "   param_kernel                                           params  \\\n",
       "0        linear                   {'C': 0.1, 'kernel': 'linear'}   \n",
       "1           rbf                      {'C': 0.1, 'kernel': 'rbf'}   \n",
       "2          poly                     {'C': 0.1, 'kernel': 'poly'}   \n",
       "3       sigmoid                  {'C': 0.1, 'kernel': 'sigmoid'}   \n",
       "4        linear                   {'C': 0.2, 'kernel': 'linear'}   \n",
       "5           rbf                      {'C': 0.2, 'kernel': 'rbf'}   \n",
       "6          poly                     {'C': 0.2, 'kernel': 'poly'}   \n",
       "7       sigmoid                  {'C': 0.2, 'kernel': 'sigmoid'}   \n",
       "8        linear   {'C': 0.30000000000000004, 'kernel': 'linear'}   \n",
       "9           rbf      {'C': 0.30000000000000004, 'kernel': 'rbf'}   \n",
       "10         poly     {'C': 0.30000000000000004, 'kernel': 'poly'}   \n",
       "11      sigmoid  {'C': 0.30000000000000004, 'kernel': 'sigmoid'}   \n",
       "12       linear                   {'C': 0.4, 'kernel': 'linear'}   \n",
       "13          rbf                      {'C': 0.4, 'kernel': 'rbf'}   \n",
       "14         poly                     {'C': 0.4, 'kernel': 'poly'}   \n",
       "15      sigmoid                  {'C': 0.4, 'kernel': 'sigmoid'}   \n",
       "16       linear                   {'C': 0.5, 'kernel': 'linear'}   \n",
       "17          rbf                      {'C': 0.5, 'kernel': 'rbf'}   \n",
       "18         poly                     {'C': 0.5, 'kernel': 'poly'}   \n",
       "19      sigmoid                  {'C': 0.5, 'kernel': 'sigmoid'}   \n",
       "20       linear                   {'C': 0.6, 'kernel': 'linear'}   \n",
       "21          rbf                      {'C': 0.6, 'kernel': 'rbf'}   \n",
       "22         poly                     {'C': 0.6, 'kernel': 'poly'}   \n",
       "23      sigmoid                  {'C': 0.6, 'kernel': 'sigmoid'}   \n",
       "24       linear    {'C': 0.7000000000000001, 'kernel': 'linear'}   \n",
       "25          rbf       {'C': 0.7000000000000001, 'kernel': 'rbf'}   \n",
       "26         poly      {'C': 0.7000000000000001, 'kernel': 'poly'}   \n",
       "27      sigmoid   {'C': 0.7000000000000001, 'kernel': 'sigmoid'}   \n",
       "28       linear                   {'C': 0.8, 'kernel': 'linear'}   \n",
       "29          rbf                      {'C': 0.8, 'kernel': 'rbf'}   \n",
       "30         poly                     {'C': 0.8, 'kernel': 'poly'}   \n",
       "31      sigmoid                  {'C': 0.8, 'kernel': 'sigmoid'}   \n",
       "32       linear                   {'C': 0.9, 'kernel': 'linear'}   \n",
       "33          rbf                      {'C': 0.9, 'kernel': 'rbf'}   \n",
       "34         poly                     {'C': 0.9, 'kernel': 'poly'}   \n",
       "35      sigmoid                  {'C': 0.9, 'kernel': 'sigmoid'}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.347826           0.347826           0.318182   \n",
       "1            0.652174           0.652174           0.636364   \n",
       "2            1.000000           0.956522           0.863636   \n",
       "3            0.347826           0.347826           0.318182   \n",
       "4            0.347826           0.391304           0.318182   \n",
       "5            0.652174           0.652174           0.636364   \n",
       "6            1.000000           0.956522           0.863636   \n",
       "7            0.347826           0.347826           0.318182   \n",
       "8            0.652174           0.652174           0.636364   \n",
       "9            0.913043           0.956522           0.727273   \n",
       "10           1.000000           1.000000           0.863636   \n",
       "11           0.347826           0.347826           0.318182   \n",
       "12           0.652174           0.652174           0.636364   \n",
       "13           0.956522           0.956522           0.909091   \n",
       "14           0.956522           1.000000           0.863636   \n",
       "15           0.347826           0.347826           0.318182   \n",
       "16           0.652174           0.652174           0.636364   \n",
       "17           1.000000           0.956522           0.863636   \n",
       "18           0.956522           1.000000           0.863636   \n",
       "19           0.347826           0.347826           0.318182   \n",
       "20           0.652174           0.652174           0.636364   \n",
       "21           1.000000           0.956522           0.863636   \n",
       "22           0.956522           1.000000           0.863636   \n",
       "23           0.347826           0.347826           0.318182   \n",
       "24           0.652174           0.652174           0.636364   \n",
       "25           1.000000           0.956522           0.863636   \n",
       "26           0.956522           1.000000           0.863636   \n",
       "27           0.347826           0.347826           0.318182   \n",
       "28           0.652174           0.652174           0.636364   \n",
       "29           1.000000           0.956522           0.863636   \n",
       "30           0.956522           1.000000           0.863636   \n",
       "31           0.347826           0.347826           0.318182   \n",
       "32           0.652174           0.652174           0.636364   \n",
       "33           1.000000           0.956522           0.863636   \n",
       "34           0.956522           1.000000           0.863636   \n",
       "35           0.347826           0.347826           0.318182   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.681818           0.681818         0.475494        0.168810   \n",
       "1            1.000000           1.000000         0.788142        0.173077   \n",
       "2            1.000000           1.000000         0.964032        0.052947   \n",
       "3            0.681818           0.681818         0.475494        0.168810   \n",
       "4            0.681818           0.727273         0.493281        0.174651   \n",
       "5            1.000000           1.000000         0.788142        0.173077   \n",
       "6            1.000000           1.000000         0.964032        0.052947   \n",
       "7            0.681818           0.681818         0.475494        0.168810   \n",
       "8            1.000000           1.000000         0.788142        0.173077   \n",
       "9            1.000000           1.000000         0.919368        0.101315   \n",
       "10           1.000000           1.000000         0.972727        0.054545   \n",
       "11           0.681818           0.681818         0.475494        0.168810   \n",
       "12           1.000000           1.000000         0.788142        0.173077   \n",
       "13           1.000000           1.000000         0.964427        0.033817   \n",
       "14           1.000000           1.000000         0.964032        0.052947   \n",
       "15           0.681818           0.681818         0.475494        0.168810   \n",
       "16           1.000000           1.000000         0.788142        0.173077   \n",
       "17           1.000000           1.000000         0.964032        0.052947   \n",
       "18           1.000000           1.000000         0.964032        0.052947   \n",
       "19           0.681818           0.681818         0.475494        0.168810   \n",
       "20           1.000000           1.000000         0.788142        0.173077   \n",
       "21           1.000000           1.000000         0.964032        0.052947   \n",
       "22           1.000000           1.000000         0.964032        0.052947   \n",
       "23           0.681818           0.681818         0.475494        0.168810   \n",
       "24           1.000000           1.000000         0.788142        0.173077   \n",
       "25           1.000000           1.000000         0.964032        0.052947   \n",
       "26           1.000000           1.000000         0.964032        0.052947   \n",
       "27           0.681818           0.681818         0.475494        0.168810   \n",
       "28           1.000000           1.000000         0.788142        0.173077   \n",
       "29           1.000000           1.000000         0.964032        0.052947   \n",
       "30           1.000000           1.000000         0.964032        0.052947   \n",
       "31           0.681818           0.681818         0.475494        0.168810   \n",
       "32           1.000000           1.000000         0.788142        0.173077   \n",
       "33           1.000000           1.000000         0.964032        0.052947   \n",
       "34           1.000000           1.000000         0.964032        0.052947   \n",
       "35           0.681818           0.681818         0.475494        0.168810   \n",
       "\n",
       "    rank_test_score  \n",
       "0                27  \n",
       "1                17  \n",
       "2                 3  \n",
       "3                27  \n",
       "4                26  \n",
       "5                17  \n",
       "6                 3  \n",
       "7                27  \n",
       "8                17  \n",
       "9                16  \n",
       "10                1  \n",
       "11               27  \n",
       "12               17  \n",
       "13                2  \n",
       "14                3  \n",
       "15               27  \n",
       "16               17  \n",
       "17                3  \n",
       "18                3  \n",
       "19               27  \n",
       "20               17  \n",
       "21                3  \n",
       "22                3  \n",
       "23               27  \n",
       "24               17  \n",
       "25                3  \n",
       "26                3  \n",
       "27               27  \n",
       "28               17  \n",
       "29                3  \n",
       "30                3  \n",
       "31               27  \n",
       "32               17  \n",
       "33                3  \n",
       "34                3  \n",
       "35               27  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 选择超参数\n",
    "param_grid = {'C': np.arange(0.1, 1, 0.1), 'kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
    "mysvm = svm.SVC()\n",
    "mysvm2 = GridSearchCV(mysvm, param_grid)\n",
    "mysvm2.fit(x_train, y_train)\n",
    "pd.DataFrame(mysvm2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "# 预测结果\n",
    "mysvm = svm.SVC(kernel='poly', C=0.3)\n",
    "mysvm.fit(x_train, y_train)\n",
    "print(mysvm.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        38\n",
      "   macro avg       1.00      1.00      1.00        38\n",
      "weighted avg       1.00      1.00      1.00        38\n",
      "\n",
      "average persion:  1.0\n",
      "F1 score:  1.0\n",
      "recall:  1.0\n",
      "acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "# 模型检验\n",
    "print(metrics.classification_report(y_test, mysvm.predict(x_test)))\n",
    "print('average persion: ', metrics.precision_score(y_test, mysvm.predict(x_test), average='macro'))\n",
    "print('F1 score: ', metrics.f1_score(y_test, mysvm.predict(x_test), average='macro'))\n",
    "print('recall: ', metrics.recall_score(y_test, mysvm.predict(x_test), average='macro'))\n",
    "print('acc: ', metrics.accuracy_score(y_test, mysvm.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.868421052631579"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 决策树分类\n",
    "# 原理：根据属性选择度量自顶向下递归构造决策树，并应用剪枝机制\n",
    "# 输入数据：\n",
    "# 优点：易于理解，树模型支持可视化，无需数据预处理（除非空值）、能够使用统计方法进行评价、开销小精度高\n",
    "# 缺点： 会受噪声影响（太深会导致overfitting），缺乏伸缩性\n",
    "# 主要参数 criterion：有基尼系数(gini)和熵(entropy)，默认基尼  max_depth:树深度，太深可能过拟合\n",
    "# 构造模型\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001725</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946245</td>\n",
       "      <td>0.044708</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.954941</td>\n",
       "      <td>0.049799</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.001725      0.000762         0.000748        0.000148   \n",
       "1       0.001333      0.000146         0.000767        0.000122   \n",
       "\n",
       "  param_criterion                    params  split0_test_score  \\\n",
       "0            gini     {'criterion': 'gini'}           0.956522   \n",
       "1         entropy  {'criterion': 'entropy'}           1.000000   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.956522           0.863636           0.954545           1.000000   \n",
       "1           0.956522           0.863636           1.000000           0.954545   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.946245        0.044708                2  \n",
       "1         0.954941        0.049799                1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 选择超参数\n",
    "param_grid = {'criterion':['gini', 'entropy']}\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf2 = GridSearchCV(clf, param_grid)\n",
    "clf2.fit(x_train, y_train)\n",
    "pd.DataFrame(clf2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.868421052631579\n",
      "[1 0 2 1 1 0 1 1 1 1 1 0 0 0 0 1 2 1 1 2 0 2 0 2 1 1 1 2 0 0 0 0 1 0 0 2 1\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "# 预测结果\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "clf = clf.fit(x_train, y_train)\n",
    "print(clf.score(x_test, y_test))\n",
    "print(clf.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.69      1.00      0.81        11\n",
      "           2       1.00      0.58      0.74        12\n",
      "\n",
      "    accuracy                           0.87        38\n",
      "   macro avg       0.90      0.86      0.85        38\n",
      "weighted avg       0.91      0.87      0.86        38\n",
      "\n",
      "average persion:  0.8958333333333334\n",
      "F1 score:  0.8505523066926576\n",
      "recall:  0.8611111111111112\n",
      "acc:  0.868421052631579\n"
     ]
    }
   ],
   "source": [
    "# 模型检验\n",
    "pred = clf.predict(x_test)\n",
    "print('average persion: ', metrics.precision_score(y_test, pred, average='macro'))\n",
    "print('F1 score: ', metrics.f1_score(y_test, pred, average='macro'))\n",
    "print('recall: ', metrics.recall_score(y_test, pred, average='macro'))\n",
    "print('acc: ', metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(223.20000000000002, 201.90857142857143, 'X[1] <= 0.423\\nentropy = 1.583\\nsamples = 112\\nvalue = [35, 39, 38]'),\n",
       " Text(167.4, 170.84571428571428, 'X[2] <= 0.563\\nentropy = 1.0\\nsamples = 77\\nvalue = [0, 39, 38]'),\n",
       " Text(111.60000000000001, 139.78285714285715, 'entropy = 0.0\\nsamples = 33\\nvalue = [0, 33, 0]'),\n",
       " Text(223.20000000000002, 139.78285714285715, 'X[1] <= 0.374\\nentropy = 0.575\\nsamples = 44\\nvalue = [0, 6, 38]'),\n",
       " Text(167.4, 108.72, 'X[3] <= 0.192\\nentropy = 0.378\\nsamples = 41\\nvalue = [0, 3, 38]'),\n",
       " Text(111.60000000000001, 77.65714285714284, 'X[2] <= 0.582\\nentropy = 0.845\\nsamples = 11\\nvalue = [0, 3, 8]'),\n",
       " Text(55.800000000000004, 46.59428571428572, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(167.4, 46.59428571428572, 'X[3] <= 0.188\\nentropy = 0.503\\nsamples = 9\\nvalue = [0, 1, 8]'),\n",
       " Text(111.60000000000001, 15.531428571428563, 'entropy = 0.0\\nsamples = 8\\nvalue = [0, 0, 8]'),\n",
       " Text(223.20000000000002, 15.531428571428563, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(223.20000000000002, 77.65714285714284, 'entropy = 0.0\\nsamples = 30\\nvalue = [0, 0, 30]'),\n",
       " Text(279.0, 108.72, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(279.0, 170.84571428571428, 'entropy = 0.0\\nsamples = 35\\nvalue = [35, 0, 0]')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree.plot_tree(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 高斯朴素贝叶斯分类\n",
    "# 原理：根据特征属性计算所有划分的条件概率，将特征所属样本概率最大的类别作为划分依据\n",
    "# 输入数据：假定特征之间相互独立。假定输入数据符合高斯分布\n",
    "# 优点：快速、简单、对于独立样本的分类准确度高，适合小规模数据集，对缺失值不敏感\n",
    "# 缺点： 独立假设比较严格，需要知道先验概率（即假设数据集已经包括了所有信息）\n",
    "# 主要参数 priors:先验概率\n",
    "# 构造模型\n",
    "clf = naive_bayes.GaussianNB()\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        38\n",
      "   macro avg       1.00      1.00      1.00        38\n",
      "weighted avg       1.00      1.00      1.00        38\n",
      "\n",
      "average persion:  1.0\n",
      "F1 score:  1.0\n",
      "recall:  1.0\n",
      "acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "# 模型检验\n",
    "pred = clf.predict(x_test)\n",
    "print('average persion: ', metrics.precision_score(y_test, pred, average='macro'))\n",
    "print('F1 score: ', metrics.f1_score(y_test, pred, average='macro'))\n",
    "print('recall: ', metrics.recall_score(y_test, pred, average='macro'))\n",
    "print('acc: ', metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2894736842105263"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分类朴素贝叶斯分类\n",
    "# 原理：根据特征属性计算所有划分的条件概率，将特征所属样本概率最大的类别作为划分依据，具有离散分布的离散特征的分类\n",
    "# 输入数据：假定特征之间相互独立。假定输入数据离散分布\n",
    "# 优点：快速、简单、对于独立样本的分类准确度高\n",
    "# 主要参数 class_prior:先验概率 alpha：拉普拉斯平滑度\n",
    "# 构造模型\n",
    "clf = naive_bayes.CategoricalNB()\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7105263157894737"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 感知机分类\n",
    "# 原理：是一种线性二项分类器，求分类的超平面。将输入数据映射为特征数据再将其映射为0-1分类，只在分类错误时更新权重（可以设置阈值）\n",
    "# 输入数据：\n",
    "# 优点：快速、可用于大数据集\n",
    "# 主要参数 penalty：正则化选项，可选l1、l2、elastic  alpha：正则化强度\n",
    "# 构造模型\n",
    "clf = linear_model.Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77        15\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.86      1.00      0.92        12\n",
      "\n",
      "    accuracy                           0.71        38\n",
      "   macro avg       0.49      0.67      0.56        38\n",
      "weighted avg       0.52      0.71      0.60        38\n",
      "\n",
      "average persion:  0.49404761904761907\n",
      "F1 score:  0.5641025641025641\n",
      "recall:  0.6666666666666666\n",
      "acc:  0.7105263157894737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 模型检验\n",
    "pred = clf.predict(x_test)\n",
    "print('average persion: ', metrics.precision_score(y_test, pred, average='macro'))\n",
    "print('F1 score: ', metrics.f1_score(y_test, pred, average='macro'))\n",
    "print('recall: ', metrics.recall_score(y_test, pred, average='macro'))\n",
    "print('acc: ', metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7105263157894737"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机梯度下降\n",
    "# 原理：每次从数据集中取出一个数据训练，相关算法有批量梯度下降和小批量梯度下降，sklearn的SGD可用在SVM和logistic上\n",
    "# 输入数据：\n",
    "# 优点：可用于大数据集\n",
    "# 缺点\n",
    "# 主要参数 loss：损失函数，根据参数选择合适的分类器或回归器，默认hinge（线性SVM） penalty：正则化选项，可选l1、l2、elastic  alpha：正则化强度\n",
    "# 构造模型\n",
    "clf = linear_model.SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008211</td>\n",
       "      <td>0.009925</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>log</td>\n",
       "      <td>{'loss': 'log'}</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.820949</td>\n",
       "      <td>0.146936</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>hinge</td>\n",
       "      <td>{'loss': 'hinge'}</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.795257</td>\n",
       "      <td>0.106298</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>{'loss': 'squared_hinge'}</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.715020</td>\n",
       "      <td>0.049168</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.008211      0.009925         0.000734        0.000095   \n",
       "1       0.002513      0.000235         0.000676        0.000028   \n",
       "2       0.002609      0.000230         0.000703        0.000050   \n",
       "\n",
       "      param_loss                     params  split0_test_score  \\\n",
       "0            log            {'loss': 'log'}           0.695652   \n",
       "1          hinge          {'loss': 'hinge'}           0.869565   \n",
       "2  squared_hinge  {'loss': 'squared_hinge'}           0.652174   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           1.000000           0.727273           0.681818           1.000000   \n",
       "1           0.652174           0.727273           0.954545           0.772727   \n",
       "2           0.695652           0.772727           0.772727           0.681818   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.820949        0.146936                1  \n",
       "1         0.795257        0.106298                2  \n",
       "2         0.715020        0.049168                3  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 选择超参数\n",
    "param_grid = {'loss': ['log', 'hinge', 'squared_hinge']}\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf2 = GridSearchCV(clf, param_grid)\n",
    "clf2.fit(x_train, y_train)\n",
    "pd.DataFrame(clf2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      1.00      0.81        15\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.75      1.00      0.86        12\n",
      "\n",
      "    accuracy                           0.71        38\n",
      "   macro avg       0.48      0.67      0.56        38\n",
      "weighted avg       0.51      0.71      0.59        38\n",
      "\n",
      "average persion:  0.47727272727272724\n",
      "F1 score:  0.555984555984556\n",
      "recall:  0.6666666666666666\n",
      "acc:  0.7105263157894737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 模型检验 \n",
    "print(metrics.classification_report(y_test, clf.predict(x_test)))\n",
    "print('average persion: ', metrics.precision_score(y_test, clf.predict(x_test), average='macro'))\n",
    "print('F1 score: ', metrics.f1_score(y_test, clf.predict(x_test), average='macro'))\n",
    "print('recall: ', metrics.recall_score(y_test, clf.predict(x_test), average='macro'))\n",
    "print('acc: ', metrics.accuracy_score(y_test, clf.predict(x_test)))\n",
    "# 经多次测试，f1值浮动很大，和每次抽取的数据有关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k-近邻分类\n",
    "# 原理：\n",
    "# 输入数据：但样本抽样不均匀时，要选择RadiusNeighborsClassifier函数创建，并提供半径r\n",
    "# 优点：可用于非线性、准确度高、不受离群值干扰、理论成熟\n",
    "# 缺点：计算量大，需要输入数据分类别平衡\n",
    "# 主要参数 n_neighbors：分几类（默认5） weights：uniform或distance，前者默认各分类平均分布 algorithm：用于计算近邻距离的算法\n",
    "# 构造模型\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_algorithm</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.002913</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'weights': 'uniform'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001306</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'weights': 'distance'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'weights': 'uniform'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'weights': 'distance'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>brute</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'brute', 'weights': 'uniform'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>brute</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'brute', 'weights': 'distance'}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.001320      0.000178         0.002913        0.000306   \n",
       "1       0.001306      0.000154         0.001701        0.000145   \n",
       "2       0.001225      0.000071         0.002994        0.000138   \n",
       "3       0.001542      0.000708         0.001666        0.000175   \n",
       "4       0.001091      0.000112         0.002867        0.000341   \n",
       "5       0.001132      0.000117         0.001480        0.000049   \n",
       "\n",
       "  param_algorithm param_weights  \\\n",
       "0       ball_tree       uniform   \n",
       "1       ball_tree      distance   \n",
       "2         kd_tree       uniform   \n",
       "3         kd_tree      distance   \n",
       "4           brute       uniform   \n",
       "5           brute      distance   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0   {'algorithm': 'ball_tree', 'weights': 'uniform'}                1.0   \n",
       "1  {'algorithm': 'ball_tree', 'weights': 'distance'}                1.0   \n",
       "2     {'algorithm': 'kd_tree', 'weights': 'uniform'}                1.0   \n",
       "3    {'algorithm': 'kd_tree', 'weights': 'distance'}                1.0   \n",
       "4       {'algorithm': 'brute', 'weights': 'uniform'}                1.0   \n",
       "5      {'algorithm': 'brute', 'weights': 'distance'}                1.0   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0                1.0           0.909091                1.0                1.0   \n",
       "1                1.0           0.909091                1.0                1.0   \n",
       "2                1.0           0.909091                1.0                1.0   \n",
       "3                1.0           0.909091                1.0                1.0   \n",
       "4                1.0           0.909091                1.0                1.0   \n",
       "5                1.0           0.909091                1.0                1.0   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.981818        0.036364                1  \n",
       "1         0.981818        0.036364                1  \n",
       "2         0.981818        0.036364                1  \n",
       "3         0.981818        0.036364                1  \n",
       "4         0.981818        0.036364                1  \n",
       "5         0.981818        0.036364                1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 选择超参数\n",
    "param_grid = {'weights': ['uniform', 'distance'], 'algorithm':['ball_tree', 'kd_tree', 'brute']}\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "clf2 = GridSearchCV(clf, param_grid)\n",
    "clf2.fit(x_train, y_train)\n",
    "pd.DataFrame(clf2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.92      1.00      0.96        11\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.97      0.97      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n",
      "average persion:  0.9722222222222222\n",
      "F1 score:  0.9710144927536232\n",
      "recall:  0.9722222222222222\n",
      "acc:  0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# 模型检验\n",
    "print(metrics.classification_report(y_test, clf.predict(x_test)))\n",
    "print('average persion: ', metrics.precision_score(y_test, clf.predict(x_test), average='macro'))\n",
    "print('F1 score: ', metrics.f1_score(y_test, clf.predict(x_test), average='macro'))\n",
    "print('recall: ', metrics.recall_score(y_test, clf.predict(x_test), average='macro'))\n",
    "print('acc: ', metrics.accuracy_score(y_test, clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 多层感知机分类器\n",
    "# 原理：基于多层感知机的后向传播算法，目前sklearn只能以最小化熵为依据减小损失函数\n",
    "# 优点：\n",
    "# 主要参数  hidden_layer_sizes：每层的神经元数量 activation：激活函数，可选logistic、tanh、relu和identity solver：优化器，可选sgd、lbfgs、adam。learning_rate:学习率\n",
    "# 构造模型\n",
    "clf = neural_network.MLPClassifier(activation='tanh', solver='lbfgs', hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.169759</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>logistic</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'logistic', 'solver': 'sgd'}</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.312648</td>\n",
       "      <td>0.006777</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.117872</td>\n",
       "      <td>0.063185</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>logistic</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.136853</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.190401</td>\n",
       "      <td>0.003777</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'logistic', 'solver': 'adam'}</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.312648</td>\n",
       "      <td>0.006777</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.168316</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'tanh', 'solver': 'sgd'}</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.642292</td>\n",
       "      <td>0.072549</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.147128</td>\n",
       "      <td>0.030166</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'tanh', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955336</td>\n",
       "      <td>0.049802</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.183567</td>\n",
       "      <td>0.006503</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'tanh', 'solver': 'adam'}</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.748221</td>\n",
       "      <td>0.096345</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'solver': 'sgd'}</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.312648</td>\n",
       "      <td>0.006777</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.348221</td>\n",
       "      <td>0.016601</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.186675</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'solver': 'adam'}</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.312648</td>\n",
       "      <td>0.006777</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.151579</td>\n",
       "      <td>0.004748</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>identity</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'identity', 'solver': 'sgd'}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.810277</td>\n",
       "      <td>0.106536</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.051517</td>\n",
       "      <td>0.039985</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>identity</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'identity', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964032</td>\n",
       "      <td>0.033918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.170710</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>identity</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'identity', 'solver': 'adam'}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.838340</td>\n",
       "      <td>0.062024</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.169759      0.004649         0.001005        0.000038   \n",
       "1        0.117872      0.063185         0.001082        0.000052   \n",
       "2        0.190401      0.003777         0.001519        0.000821   \n",
       "3        0.168316      0.003318         0.001090        0.000039   \n",
       "4        0.147128      0.030166         0.001157        0.000073   \n",
       "5        0.183567      0.006503         0.001167        0.000105   \n",
       "6        0.162162      0.003892         0.001194        0.000220   \n",
       "7        0.006554      0.001921         0.001046        0.000145   \n",
       "8        0.186675      0.002529         0.001416        0.000318   \n",
       "9        0.151579      0.004748         0.001212        0.000155   \n",
       "10       0.051517      0.039985         0.001002        0.000011   \n",
       "11       0.170710      0.000960         0.001259        0.000177   \n",
       "\n",
       "   param_activation param_solver  \\\n",
       "0          logistic          sgd   \n",
       "1          logistic        lbfgs   \n",
       "2          logistic         adam   \n",
       "3              tanh          sgd   \n",
       "4              tanh        lbfgs   \n",
       "5              tanh         adam   \n",
       "6              relu          sgd   \n",
       "7              relu        lbfgs   \n",
       "8              relu         adam   \n",
       "9          identity          sgd   \n",
       "10         identity        lbfgs   \n",
       "11         identity         adam   \n",
       "\n",
       "                                           params  split0_test_score  \\\n",
       "0     {'activation': 'logistic', 'solver': 'sgd'}           0.304348   \n",
       "1   {'activation': 'logistic', 'solver': 'lbfgs'}           0.956522   \n",
       "2    {'activation': 'logistic', 'solver': 'adam'}           0.304348   \n",
       "3         {'activation': 'tanh', 'solver': 'sgd'}           0.695652   \n",
       "4       {'activation': 'tanh', 'solver': 'lbfgs'}           0.956522   \n",
       "5        {'activation': 'tanh', 'solver': 'adam'}           0.869565   \n",
       "6         {'activation': 'relu', 'solver': 'sgd'}           0.304348   \n",
       "7       {'activation': 'relu', 'solver': 'lbfgs'}           0.347826   \n",
       "8        {'activation': 'relu', 'solver': 'adam'}           0.304348   \n",
       "9     {'activation': 'identity', 'solver': 'sgd'}           0.956522   \n",
       "10  {'activation': 'identity', 'solver': 'lbfgs'}           0.956522   \n",
       "11   {'activation': 'identity', 'solver': 'adam'}           0.956522   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.304348           0.318182           0.318182   \n",
       "1            1.000000           0.863636           0.636364   \n",
       "2            0.304348           0.318182           0.318182   \n",
       "3            0.652174           0.500000           0.681818   \n",
       "4            0.956522           0.863636           1.000000   \n",
       "5            0.826087           0.772727           0.636364   \n",
       "6            0.304348           0.318182           0.318182   \n",
       "7            0.347826           0.318182           0.363636   \n",
       "8            0.304348           0.318182           0.318182   \n",
       "9            0.913043           0.772727           0.727273   \n",
       "10           1.000000           0.909091           0.954545   \n",
       "11           0.826087           0.818182           0.818182   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.318182         0.312648        0.006777                9  \n",
       "1            1.000000         0.891304        0.136853                3  \n",
       "2            0.318182         0.312648        0.006777                9  \n",
       "3            0.681818         0.642292        0.072549                7  \n",
       "4            1.000000         0.955336        0.049802                2  \n",
       "5            0.636364         0.748221        0.096345                6  \n",
       "6            0.318182         0.312648        0.006777                9  \n",
       "7            0.363636         0.348221        0.016601                8  \n",
       "8            0.318182         0.312648        0.006777                9  \n",
       "9            0.681818         0.810277        0.106536                5  \n",
       "10           1.000000         0.964032        0.033918                1  \n",
       "11           0.772727         0.838340        0.062024                4  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 选择超参数\n",
    "param_grid = {'activation':['logistic', 'tanh', 'relu', 'identity'], 'solver':['sgd', 'lbfgs', 'adam']}\n",
    "clf = neural_network.MLPClassifier(hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf2 = GridSearchCV(clf, param_grid)\n",
    "clf2.fit(x_train, y_train)\n",
    "pd.DataFrame(clf2.cv_results_)\n",
    "# 最好的是 logistic+lbfgs 和 tanh + lbfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        38\n",
      "   macro avg       1.00      1.00      1.00        38\n",
      "weighted avg       1.00      1.00      1.00        38\n",
      "\n",
      "average persion:  1.0\n",
      "F1 score:  1.0\n",
      "recall:  1.0\n",
      "acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "# 模型检验\n",
    "print(metrics.classification_report(y_test, clf.predict(x_test)))\n",
    "print('average persion: ', metrics.precision_score(y_test, clf.predict(x_test), average='macro'))\n",
    "print('F1 score: ', metrics.f1_score(y_test, clf.predict(x_test), average='macro'))\n",
    "print('recall: ', metrics.recall_score(y_test, clf.predict(x_test), average='macro'))\n",
    "print('acc: ', metrics.accuracy_score(y_test, clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baggingClassfier\n",
    "bagging = ensemble.BaggingClassifier(neighbors.KNeighborsClassifier(),max_samples=0.5, max_features=0.5)\n",
    "bagging.fit(x_train, y_train)\n",
    "bagging.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        38\n",
      "   macro avg       1.00      1.00      1.00        38\n",
      "weighted avg       1.00      1.00      1.00        38\n",
      "\n",
      "average persion:  1.0\n",
      "F1 score:  1.0\n",
      "recall:  1.0\n",
      "acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "# 模型检验\n",
    "print(metrics.classification_report(y_test, bagging.predict(x_test)))\n",
    "print('average persion: ', metrics.precision_score(y_test, bagging.predict(x_test), average='macro'))\n",
    "print('F1 score: ', metrics.f1_score(y_test, bagging.predict(x_test), average='macro'))\n",
    "print('recall: ', metrics.recall_score(y_test, bagging.predict(x_test), average='macro'))\n",
    "print('acc: ', metrics.accuracy_score(y_test, bagging.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=10)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.85      1.00      0.92        11\n",
      "           2       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.95      0.94      0.94        38\n",
      "weighted avg       0.96      0.95      0.95        38\n",
      "\n",
      "average persion:  0.9487179487179488\n",
      "F1 score:  0.9419191919191919\n",
      "recall:  0.9444444444444445\n",
      "acc:  0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# 模型检验\n",
    "print(metrics.classification_report(y_test, clf.predict(x_test)))\n",
    "print('average persion: ', metrics.precision_score(y_test, clf.predict(x_test), average='macro'))\n",
    "print('F1 score: ', metrics.f1_score(y_test, clf.predict(x_test), average='macro'))\n",
    "print('recall: ', metrics.recall_score(y_test, clf.predict(x_test), average='macro'))\n",
    "print('acc: ', metrics.accuracy_score(y_test, clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.868421052631579"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AdaBoost\n",
    "lr = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "clf = ensemble.AdaBoostClassifier(base_estimator=lr, n_estimators=100)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.69      1.00      0.81        11\n",
      "           2       1.00      0.58      0.74        12\n",
      "\n",
      "    accuracy                           0.87        38\n",
      "   macro avg       0.90      0.86      0.85        38\n",
      "weighted avg       0.91      0.87      0.86        38\n",
      "\n",
      "average persion:  0.8958333333333334\n",
      "F1 score:  0.8505523066926576\n",
      "recall:  0.8611111111111112\n",
      "acc:  0.868421052631579\n"
     ]
    }
   ],
   "source": [
    "# 模型检验\n",
    "print(metrics.classification_report(y_test, clf.predict(x_test)))\n",
    "print('average persion: ', metrics.precision_score(y_test, clf.predict(x_test), average='macro'))\n",
    "print('F1 score: ', metrics.f1_score(y_test, clf.predict(x_test), average='macro'))\n",
    "print('recall: ', metrics.recall_score(y_test, clf.predict(x_test), average='macro'))\n",
    "print('acc: ', metrics.accuracy_score(y_test, clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBDT\n",
    "clf = ensemble.GradientBoostingClassifier(n_estimators=500, learning_rate=1.0)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.92      1.00      0.96        11\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.97      0.97      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n",
      "average persion:  0.9722222222222222\n",
      "F1 score:  0.9710144927536232\n",
      "recall:  0.9722222222222222\n",
      "acc:  0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# 模型检验\n",
    "print(metrics.classification_report(y_test, clf.predict(x_test)))\n",
    "print('average persion: ', metrics.precision_score(y_test, clf.predict(x_test), average='macro'))\n",
    "print('F1 score: ', metrics.f1_score(y_test, clf.predict(x_test), average='macro'))\n",
    "print('recall: ', metrics.recall_score(y_test, clf.predict(x_test), average='macro'))\n",
    "print('acc: ', metrics.accuracy_score(y_test, clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# voting classifier\n",
    "clf1 = linear_model.LogisticRegression(random_state=1)\n",
    "clf2 = ensemble.RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = naive_bayes.GaussianNB()\n",
    "eclf = ensemble.VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "eclf.fit(x_train, y_train)\n",
    "eclf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        38\n",
      "   macro avg       1.00      1.00      1.00        38\n",
      "weighted avg       1.00      1.00      1.00        38\n",
      "\n",
      "average persion:  1.0\n",
      "F1 score:  1.0\n",
      "recall:  1.0\n",
      "acc:  1.0\n"
     ]
    }
   ],
   "source": [
    "# 模型检验\n",
    "print(metrics.classification_report(y_test, eclf.predict(x_test)))\n",
    "print('average persion: ', metrics.precision_score(y_test, eclf.predict(x_test), average='macro'))\n",
    "print('F1 score: ', metrics.f1_score(y_test, eclf.predict(x_test), average='macro'))\n",
    "print('recall: ', metrics.recall_score(y_test, eclf.predict(x_test), average='macro'))\n",
    "print('acc: ', metrics.accuracy_score(y_test, eclf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "xg_train = xgb.DMatrix(x_train, label=y_train)\n",
    "xg_test = xgb.DMatrix(x_test, label=y_test)\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 6\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 4\n",
    "param['num_class'] = 6\n",
    "clf = xgb.train(param, xg_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 2., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 2.,\n",
       "       1., 1., 2., 0., 2., 0., 2., 2., 1., 2., 2., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 2., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(xg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.79      1.00      0.88        11\n",
      "           2       1.00      0.75      0.86        12\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        38\n",
      "   macro avg       0.93      0.92      0.91        38\n",
      "weighted avg       0.94      0.92      0.92        38\n",
      "\n",
      "average persion:  0.9285714285714285\n",
      "F1 score:  0.9123809523809524\n",
      "recall:  0.9166666666666666\n",
      "acc:  0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "# 模型检验\n",
    "pred = clf.predict(xg_test)\n",
    "print(metrics.classification_report(y_test, pred))\n",
    "print('average persion: ', metrics.precision_score(y_test, pred, average='macro'))\n",
    "print('F1 score: ', metrics.f1_score(y_test, pred, average='macro'))\n",
    "print('recall: ', metrics.recall_score(y_test, pred, average='macro'))\n",
    "print('acc: ', metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 1, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LightBGM\n",
    "clf = lgb.LGBMClassifier(num_class=3, objective='multiclass')\n",
    "clf.fit(x_train, y_train)\n",
    "clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.92      1.00      0.96        11\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        38\n",
      "   macro avg       0.97      0.97      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n",
      "average persion:  0.9722222222222222\n",
      "F1 score:  0.9710144927536232\n",
      "recall:  0.9722222222222222\n",
      "acc:  0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# 模型检验\n",
    "pred = clf.predict(x_test)\n",
    "print(metrics.classification_report(y_test, pred))\n",
    "print('average persion: ', metrics.precision_score(y_test, pred, average='macro'))\n",
    "print('F1 score: ', metrics.f1_score(y_test, pred, average='macro'))\n",
    "print('recall: ', metrics.recall_score(y_test, pred, average='macro'))\n",
    "print('acc: ', metrics.accuracy_score(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
